# 模板匹配的车牌识别系统
## 开发工具
语言：Python3.12

主要的python库：Matplotlib、NumPy、OpenCV、Pillow

环境：可自己搭建，也可以使用conda默认环境

## 文件解读
template_data：模板集

test_data：测试集

learn_data：更庞大的模板集

## 运行
直接打开py文件即可，不过需要修改模板集和测试集路径参数再运行

## 原理
模板匹配是一种在图像处理中用于查找与给定模板图像（Template Image）最相似区域的算法。它的核心思想是通过滑动模板图像在目标图像（Source Image）上移动，计算每个位置的相似度，评分，最终找到与模板最匹配的区域。

计算方法如下：

平方差匹配（SQDIFF）：计算模板与目标区域的像素值差的平方和。

归一化平方差匹配（SQDIFF_NORMED）：对平方差进行归一化处理。

相关性匹配（CCORR）：计算模板与目标区域的像素值乘积和。

归一化相关性匹配（CCORR_NORMED）：对相关性进行归一化处理。

相关系数匹配（CCOEFF）：计算模板与目标区域的相关系数。

归一化相关系数匹配（CCOEFF_NORMED）：对相关系数进行归一化处理。

实现的程序中，我使用了归一化相关系数匹配方法，即cv2.TM_CCOEFF_NORMED。

## 结果分析
最终，根据我的代码，会输出排名前五的最佳匹配结果。
但显然，这样做并不符合初心，因为车牌识别肯定是要取最佳的匹配，直接实现的。查阅资料，我发现可能是模板集太少的问题，但即使拿更庞大的模板集learn_data进行模板匹配，准确率也不高，也可能是模板匹配根据像素匹配，本身就有缺陷性，尤其是对光线、旋转之类的改变较为敏感。

因此，如果想要更好地进行车牌识别，应该用学习匹配的方法，如卷积神经网络。
